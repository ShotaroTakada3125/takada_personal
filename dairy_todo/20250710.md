## todo
- CSVサニタイズ案件
- 目標変更
- 合宿関連


## 各タスク進捗
- 目標について
    - 4点については変えた方が良いが、3点の延長としての4点の良い候補が思い浮かばない
    - 4点の方向性：他者に良い影響を与える、という他者を巻き込むという方向性
    - 1年目の学びやプロセスを会社の資産にするというのは新卒研修で使う必要はない
    - 評価の仕方が難しい。来年度の話なので、評価自体はできるとはいえ、難しい。
    - 成果目標の二つに関しては書き直す
    - 一年目の取り組みを後の世代のために自分が得たプロセスを共有する。取り組みの一つとして成果物を作る。
    - 目標をぼかす。成果物は取り組みの一つとして再考する。
    - 期限は7月中にまとめられたら良い、面談再設定の話はおいおい。
    - 7/18までに提出。

- 合宿案件
    - 手順書1
        目的：Google Cloud Speech-to-Textサービスを利用して、音声ファイルをテキストに文字起こしする
        手順
        1.  Google Cloud Consoleにアクセス
            hogehoge
        2. 新しいプロジェクトの作成
        3. 必要なAPIの有効化
            1. Cloud Speech-to Text APIの有効化
            2. Vertex AI APIの有効化
        4. サービスアカウントの作成と認証情報キーのダウンロード
            1. サービスアカウントのページにアクセス
            2. サービスアカウントを作成
            3. サービスアカウント名を入力し、作成して実行を押下
            4. 「このサービス アカウントにプロジェクトへのアクセスを許可する」セクションで、以下の3つのロールを付与
                - Cloud Speech と検索し、「Cloud Speech クライアント」を選択
                - Vertex AI と検索し、「Vertex AI ユーザー」を選択
                - ストレージ と検索し、「環境とストレージ オブジェクト閲覧者」を選択
            5. 「続行」をクリックし、次の画面で「完了」をクリック

        5. 

    ## 現状（AS-IS）

    現在のシステムは、Pythonスクリプトとして提供されており、以下の手順で実行可能です。

    1.  Google Cloud Platform (GCP) プロジェクトのセットアップ、API有効化、サービスアカウント作成とJSONキーダウンロード。
    2.  Python環境の準備（Pythonインストール、仮想環境作成、ライブラリインストール）。
    3.  FFmpegのインストールと音声ファイルのFLAC形式への変換。
    4.  FLAC音声ファイルのGCP Cloud Storageへのアップロード。
    5.  JSONキーファイルのローカル配置と環境変数設定。
    6.  `config.py`で各種設定（プロジェクトID、GGCS URI、モデル名、カスタムフレーズ、プロンプト）を編集。
    7.  `speech_transcriber.py`スクリプトをターミナルから実行。
    8.  文字起こし結果がターミナルに出力される。

    ---

    ## 理想の姿（TO-BE）：ユーザー目線でのツール化

    現在の環境は開発者にとっては柔軟性が高いですが、一般ユーザーが手軽に利用するには多くの専門知識と手間が必要です。これを「ツール」として実行できるようにするためには、ユーザーが意識する手順を大幅に削減し、直感的な操作で結果を得られるようにする必要があります。

    ### ユーザーがやりたいこと

    ユーザーが最終的にやりたいことは、おそらく以下のシンプルなステップです。

    1.  **音声ファイルを選択する。**
    2.  **実行ボタンを押す。**
    3.  **文字起こし結果（と可能であれば議事録）を受け取る。**

    ### TO-BE ツールとしての検討

    上記の「ユーザーがやりたいこと」を実現するためには、現在の裏側の複雑なプロセスをツールが吸収し、ユーザーからは見えなくする必要があります。

    #### ユーザーインターフェース (UI) の検討

    * **GUI (Graphical User Interface)**: 最も直感的で、プログラミング知識がないユーザーでも利用できます。Windows、macOS、Linuxで動作するデスクトップアプリケーションや、WebブラウザでアクセスできるWebアプリケーションが考えられます。
        * **候補技術**: Streamlit, Flask/Django + HTML/CSS/JavaScript (Webアプリ), PyQt/Tkinter (デスクトップアプリ)
    * **CLI (Command Line Interface) with improved UX**: コマンドラインに慣れているユーザー向けですが、現在のPythonスクリプトよりは洗練されたもの。引数でファイルを指定したり、設定を渡したりする形式。
        * **候補技術**: Click, argparse (Pythonライブラリ)

    #### ユーザー体験 (UX) の改善点

    1.  **インストールと初期設定の簡素化**:
        * GCP認証情報のセットアップ手順は避けられないものの、初回の一度だけで済むようにする。可能であれば、GUIからJSONファイルを直接指定できるようにする。
        * Python環境やFFmpegのインストールを自動化、またはガイドを分かりやすく提示する。
    2.  **入力の簡素化**:
        * 音声ファイルをドラッグ＆ドロップまたはファイル選択ダイアログで指定。
        * GCSへのアップロードはツールが自動で行う。ユーザーはGCSバケット名を意識しない。
        * カスタムフレーズは、ツール内の入力フォームで直接入力できるか、CSV/テキストファイルとしてアップロードできるようにする。
        * プロンプトの調整も、ツール内のテキストエリアで編集できるようにする。
    3.  **実行と進捗表示**:
        * 「文字起こし開始」ボタン一つで実行。
        * 現在の処理状況（「Cloud Speech-to-Textで処理中...」「Gemini Flashで解析中...」「最終整形中...」）をリアルタイムで表示し、ユーザーが待っている間に不安にならないようにする。
    4.  **出力の改善**:
        * 文字起こし結果や整形された議事録テキストを、ツール内に表示する。
        * 結果をファイル（`.txt`, `.md`, `.docx` など）としてダウンロードできる機能を提供する。
        * 結果の整形形式（議事録、要約、Q&Aなど）をオプションで選択できるようにする。
    5.  **エラーハンドリング**:
        * 発生したエラーをユーザーに分かりやすい言葉で表示し、対処法を提示する。
        * ログは裏側で保存し、必要に応じてユーザーが確認できるようにする。

    #### TO-BEの具体的な姿（例: Webアプリケーションの場合）

    1.  ユーザーはツールを起動（またはWebブラウザでURLにアクセス）。
    2.  初回起動時のみ、GCPのJSONキーファイルを選択して設定保存。
    3.  ツール画面に「音声ファイルを選択」ボタンとドラッグ＆ドロップエリアが表示される。
    4.  カスタムフレーズを入力するテキストエリアや、プロンプトを編集するエリアがある。
    5.  ユーザーが音声ファイルをアップロード。
    6.  「文字起こし開始」ボタンをクリック。
    7.  プログレスバーやテキストで処理状況が表示される。
    8.  処理完了後、画面上に整形された議事録テキストが表示され、「ダウンロード」ボタンで保存できる。

    ### 次のステップの提案

    これらの「やりたいこと」と「TO-BE」を踏まえると、次に着手すべきは、やはり「**ファイル出力機能**」と「**エラーハンドリングの強化**」です。これらはGUI化する上でも基盤となる重要な機能であり、現在のスクリプトをより実用的にするためにも不可欠です。

    特に、プロンプトで指示したGitHub Issue形式の出力は、そのままファイルに保存できると非常に便利です。

    いかがでしょうか？このTO-BE像を参考に、次のステップに進んでいきましょう。